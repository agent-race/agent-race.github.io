<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><script data-mantine-script="true">try {
  var _colorScheme = window.localStorage.getItem("mantine-color-scheme-value");
  var colorScheme = _colorScheme === "light" || _colorScheme === "dark" || _colorScheme === "auto" ? _colorScheme : "auto";
  var computedColorScheme = colorScheme !== "auto" ? colorScheme : window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
  document.documentElement.setAttribute("data-mantine-color-scheme", computedColorScheme);
} catch (e) {}
</script><link rel="preload" href="/_next/static/css/e55422db8ef0350a.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/e55422db8ef0350a.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/cf90bf3fc73fec57.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/cf90bf3fc73fec57.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-2c1f25ac8a9585fc.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-2c3044221d39fe2c.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-a5e61fdd3daae839.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-a728986f309b03d5.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/721-bab849efef7d2e94.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/596-9bd2a7537c835045.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/bugsandfeatures-5e79a4ae89c7e63f.js" defer="" crossorigin=""></script><script src="/_next/static/hqgkvujuo8_0LJtgbprH8/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/hqgkvujuo8_0LJtgbprH8/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><header class="header_header__zJOD0"><title>AgentRace: Benchmarking Efficiency in LLM Agent Frameworks</title><meta property="og:title" content="AgentRace: Benchmarking Efficiency in LLM Agent Frameworks"/><meta property="og:description" content="A toolkit crafted specifically for the systematic evaluation of data privacy risks in LLMs, incorporating diverse attack and defense strategies, and handling various data types and metrics."/><div style="--container-size:var(--container-size-md)" class="header_inner__Gca1C m-7485cace mantine-Container-root" data-size="md"><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-visible-from-xs">AgentRace: Benchmarking Efficiency in LLM Agent Frameworks</p><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-hidden-from-xs">AgentRace</p> <div style="--group-gap:calc(0.3125rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="m-4081bf90 mantine-Group-root mantine-visible-from-md"><a href="/home" class="header_link__ne2MS"><div style="display:flex;gap:4px">Home</div></a><a href="/insights" class="header_link__ne2MS"><div style="display:flex;gap:4px">Insights</div></a><a href="/bugsandfeatures" class="header_link__ne2MS" data-active="true"><div style="display:flex;gap:4px">Bugs/Features</div></a><a href="/paper" class="header_link__ne2MS"><div style="display:flex;gap:4px">Paper</div></a><a href="https://github.com/agent-race/AgentRace" class="header_link__ne2MS"><div style="display:flex;gap:4px">GitHub<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-external-link" style="width:14px;height:14px"><path d="M12 6h-6a2 2 0 0 0 -2 2v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-6"></path><path d="M11 13l9 -9"></path><path d="M15 4h5v5"></path></svg></div></a></div><button style="--burger-size:var(--burger-size-md)" class="mantine-focus-auto m-fea6bf1a mantine-Burger-root m-87cf2631 mantine-UnstyledButton-root mantine-hidden-from-md" data-size="md" type="button" aria-haspopup="menu" aria-expanded="false" aria-controls="mantine-R5m3m-dropdown" id="mantine-R5m3m-target"><div class="m-d4fb9cad mantine-Burger-burger" data-reduce-motion="true"></div></button></div><script async="" src="https://us.umami.is/script.js" data-website-id="5d999a58-aa74-47db-897c-1c811cb73612"></script><script defer="" src="https://umami.xtra.science/script.js" data-website-id="81e4d054-90e2-428a-af65-f0a20b460201"></script></header><div style="height:calc(3.5rem * var(--mantine-scale))"> <!-- --> </div><main><div class="m-7485cace mantine-Container-root"><h1 style="--title-fw:var(--mantine-h1-font-weight);--title-lh:var(--mantine-h1-line-height);--title-fz:var(--mantine-h1-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="1">Bugs/Features</h1><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">This page summarizes the observed abnormal behaviours of studied frameworks during our experiments.<br/></p><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">LangChain</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;margin-right:auto;margin-left:auto;width:50%;height:auto" class="m-9e117634 mantine-Image-root" src="langchain_abs.png" alt="defenses"/><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">LangChain&#x27;s high level of abstraction and encapsulation posed challenges in measuring specific metrics during our experiments.<br/></p><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;margin-right:auto;margin-left:auto;width:100%;height:auto" class="m-9e117634 mantine-Image-root" src="langchain_bug.png" alt="defenses"/><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Additionally, LangChain occasionally terminated processes prematurely after reading files from the GAIA dataset, returning the file content directly rather than proceeding with the expected operations.</p></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">AutoGen</h2><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Due to the default system prompt being relatively long and containing irrelevant instructions, the RAG workflow may consume unnecessary tokens or produce unexpected errors (e.g., attempting to invoke non-existent tools). Therefore, it is necessary for users to customize the system prompt.</p><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">AgentScope</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">AgentScope’s image and audio processing tools internally rely on OpenAI models, causing their execution time to partially overlap with that of the LLM itself. This overlap can lead to inflated or inaccurate measurements of LLM processing time. Researchers and practitioners should be mindful of this issue when conducting time-based evaluations involving AgentScope.<br/></p><div class="m-5cb1b9c8 m-1f5e827e mantine-CodeHighlight-root" dir="ltr"><button class="mantine-focus-auto mantine-active m-5caae85b mantine-CodeHighlight-copy m-8d3f4000 mantine-ActionIcon-root m-87cf2631 mantine-UnstyledButton-root" data-variant="none" type="button"><svg xmlns="http://www.w3.org/2000/svg" style="width:calc(1.125rem * var(--mantine-scale));height:calc(1.125rem * var(--mantine-scale))" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M8 8m0 2a2 2 0 0 1 2 -2h8a2 2 0 0 1 2 2v8a2 2 0 0 1 -2 2h-8a2 2 0 0 1 -2 -2z"></path><path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path></svg></button><div style="--sa-corner-width:0px;--sa-corner-height:0px" class="m-d57069b5 mantine-ScrollArea-root" dir="ltr"><div style="overflow-x:hidden;overflow-y:hidden" class="m-c0783ff9 mantine-ScrollArea-viewport" data-scrollbars="xy"><div style="min-width:100%;display:table"><pre class="m-2c47c4fd mantine-CodeHighlight-pre"><code class="m-5caae6d3 mantine-CodeHighlight-code"><span class="hljs-keyword">def</span> <span class="hljs-title function_">openai_image_to_text</span>(<span class="hljs-params">
    image_urls: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]],
    api_key: <span class="hljs-built_in">str</span>,
    prompt: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;Describe the image&quot;</span>,
    model: <span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;gpt-4o&quot;</span>, <span class="hljs-string">&quot;gpt-4-turbo&quot;</span>] = <span class="hljs-string">&quot;gpt-4o&quot;</span>,
</span>) -&gt; ServiceResponse:
    <span class="hljs-string">&quot;&quot;&quot;
    Generate descriptive text for given image(s) using a specified model, and
    return the generated text.

    Args:
        image_urls (`Union[str, list[str]]`):
            The URL or list of URLs pointing to the images that need to be
            described.
        api_key (`str`):
            The API key for the OpenAI API.
        prompt (`str`, defaults to `&quot;Describe the image&quot;`):
            The prompt that instructs the model on how to describe
            the image(s).
        model (`Literal[&quot;gpt-4o&quot;, &quot;gpt-4-turbo&quot;]`, defaults to `&quot;gpt-4o&quot;`):
            The model to use for generating the text descriptions.

    Returns:
        `ServiceResponse`:
            A dictionary with two variables: `status` and `content`.
            If `status` is `ServiceExecStatus.SUCCESS`,
            the `content` contains the generated text description(s).

    Example:

        .. code-block:: python

            image_url = &quot;https://example.com/image.jpg&quot;
            api_key = &quot;YOUR_API_KEY&quot;
            print(openai_image_to_text(image_url, api_key))

        &gt; {
        &gt;     &#x27;status&#x27;: &#x27;SUCCESS&#x27;,
        &gt;     &#x27;content&#x27;: &quot;A detailed description of the image...&quot;
        &gt; }
    &quot;&quot;&quot;</span>
    openai_chat_wrapper = OpenAIChatWrapper(
        config_name=<span class="hljs-string">&quot;image_to_text_service_call&quot;</span>,
        model_name=model,
        api_key=api_key,
    )
    messages = Msg(
        name=<span class="hljs-string">&quot;service_call&quot;</span>,
        role=<span class="hljs-string">&quot;user&quot;</span>,
        content=prompt,
        url=image_urls,
    )
    openai_messages = openai_chat_wrapper.<span class="hljs-built_in">format</span>(messages)
    <span class="hljs-keyword">try</span>:
        response = openai_chat_wrapper(openai_messages)
        <span class="hljs-keyword">return</span> ServiceResponse(ServiceExecStatus.SUCCESS, response.text)
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        <span class="hljs-keyword">return</span> ServiceResponse(ServiceExecStatus.ERROR, <span class="hljs-built_in">str</span>(e))

<span class="hljs-keyword">def</span> <span class="hljs-title function_">openai_audio_to_text</span>(<span class="hljs-params">
    audio_file_url: <span class="hljs-built_in">str</span>,
    api_key: <span class="hljs-built_in">str</span>,
    language: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;en&quot;</span>,
    temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.2</span>,
</span>) -&gt; ServiceResponse:
    <span class="hljs-string">&quot;&quot;&quot;
    Convert an audio file to text using OpenAI&#x27;s transcription service.

    Args:
        audio_file_url (`str`):
            The file path or URL to the audio file that needs to be
            transcribed.
        api_key (`str`):
            The API key for the OpenAI API.
        language (`str`, defaults to `&quot;en&quot;`):
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
            format will improve accuracy and latency.
        temperature (`float`, defaults to `0.2`):
            The temperature for the transcription, which affects the
            randomness of the output.

    Returns:
        `ServiceResponse`:
            A dictionary with two variables: `status` and `content`.
            If `status` is `ServiceExecStatus.SUCCESS`,
            the `content` contains a dictionary with key &#x27;transcription&#x27; and
            value as the transcribed text.

    Example:

        .. code-block:: python

            audio_file_url = &quot;/path/to/audio.mp3&quot;
            api_key = &quot;YOUR_API_KEY&quot;
            print(openai_audio_to_text(audio_file_url, api_key))

        &gt; {
        &gt;     &#x27;status&#x27;: &#x27;SUCCESS&#x27;,
        &gt;     &#x27;content&#x27;: {&#x27;transcription&#x27;: &#x27;This is the transcribed text from
        the audio file.&#x27;}
        &gt; }
    &quot;&quot;&quot;</span>
    <span class="hljs-keyword">try</span>:
        <span class="hljs-keyword">import</span> openai
    <span class="hljs-keyword">except</span> ImportError <span class="hljs-keyword">as</span> e:
        <span class="hljs-keyword">raise</span> ImportError(
            <span class="hljs-string">&quot;The `openai` library is not installed. Please install it by &quot;</span>
            <span class="hljs-string">&quot;running `pip install openai`.&quot;</span>,
        ) <span class="hljs-keyword">from</span> e

    client = openai.OpenAI(api_key=api_key)
    audio_file_url = os.path.abspath(audio_file_url)
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(audio_file_url, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> audio_file:
        <span class="hljs-keyword">try</span>:
            transcription = client.audio.transcriptions.create(
                model=<span class="hljs-string">&quot;whisper-1&quot;</span>,
                file=audio_file,
                language=language,
                temperature=temperature,
            )
            <span class="hljs-keyword">return</span> ServiceResponse(
                ServiceExecStatus.SUCCESS,
                {<span class="hljs-string">&quot;transcription&quot;</span>: transcription.text},
            )
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            <span class="hljs-keyword">return</span> ServiceResponse(
                ServiceExecStatus.ERROR,
                <span class="hljs-string">f&quot;Error: Failed to transcribe audio <span class="hljs-subst">{<span class="hljs-built_in">str</span>(e)}</span>&quot;</span>,
)</code></pre></div></div></div></div><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Meanwhile, AgentScope&#x27;s vector database module, LlamaIndexKnowledge, is implemented based on the BM25Retriever from the llamaindex library. However, the original implementation relies on an outdated version of llamaindex, and recent updates to the library introduced structural changes that break compatibility with the original import statements.<br/></p><div class="m-5cb1b9c8 m-1f5e827e mantine-CodeHighlight-root" dir="ltr"><button class="mantine-focus-auto mantine-active m-5caae85b mantine-CodeHighlight-copy m-8d3f4000 mantine-ActionIcon-root m-87cf2631 mantine-UnstyledButton-root" data-variant="none" type="button"><svg xmlns="http://www.w3.org/2000/svg" style="width:calc(1.125rem * var(--mantine-scale));height:calc(1.125rem * var(--mantine-scale))" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M8 8m0 2a2 2 0 0 1 2 -2h8a2 2 0 0 1 2 2v8a2 2 0 0 1 -2 2h-8a2 2 0 0 1 -2 -2z"></path><path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path></svg></button><div style="--sa-corner-width:0px;--sa-corner-height:0px" class="m-d57069b5 mantine-ScrollArea-root" dir="ltr"><div style="overflow-x:hidden;overflow-y:hidden" class="m-c0783ff9 mantine-ScrollArea-viewport" data-scrollbars="xy"><div style="min-width:100%;display:table"><pre class="m-2c47c4fd mantine-CodeHighlight-pre"><code class="m-5caae6d3 mantine-CodeHighlight-code"><span class="hljs-keyword">from</span> llama_index.retrievers.bm25 <span class="hljs-keyword">import</span> BM25Retriever</code></pre></div></div></div></div><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">To ensure a consistent environment without modifying the framework’s built-in vector database logic, we resolved the issue by duplicating the LlamaIndexKnowledge module and updating the import paths to match the newer llamaindex version.</p><div class="m-5cb1b9c8 m-1f5e827e mantine-CodeHighlight-root" dir="ltr"><button class="mantine-focus-auto mantine-active m-5caae85b mantine-CodeHighlight-copy m-8d3f4000 mantine-ActionIcon-root m-87cf2631 mantine-UnstyledButton-root" data-variant="none" type="button"><svg xmlns="http://www.w3.org/2000/svg" style="width:calc(1.125rem * var(--mantine-scale));height:calc(1.125rem * var(--mantine-scale))" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M8 8m0 2a2 2 0 0 1 2 -2h8a2 2 0 0 1 2 2v8a2 2 0 0 1 -2 2h-8a2 2 0 0 1 -2 -2z"></path><path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path></svg></button><div style="--sa-corner-width:0px;--sa-corner-height:0px" class="m-d57069b5 mantine-ScrollArea-root" dir="ltr"><div style="overflow-x:hidden;overflow-y:hidden" class="m-c0783ff9 mantine-ScrollArea-viewport" data-scrollbars="xy"><div style="min-width:100%;display:table"><pre class="m-2c47c4fd mantine-CodeHighlight-pre"><code class="m-5caae6d3 mantine-CodeHighlight-code"><span class="hljs-keyword">from</span> llama_index.legacy.retrievers.bm25_retriever <span class="hljs-keyword">import</span> BM25Retriever</code></pre></div></div></div></div></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">CrewAI</h2><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">When our MOA invokes a large number of agents (&gt;=12), CrewAI system occasionally fails to call all agents completely during execution as intended. For example, when we request 12 sub-agents to be activated, some queries may only trigger 9 or fewer agents.</p><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">Llamaindex</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;margin-right:auto;margin-left:auto;width:75%;height:auto" class="m-9e117634 mantine-Image-root" src="llamaindex_bug.jpg" alt="radar"/><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">LlamaIndex frequently fails to invoke tools correctly, primarily due to the lack of prompt constraints and insufficient post-processing checks on LLM outputs. Without explicit guidance and validation mechanisms, the LLM often produces outputs that do not conform to the expected dictionary format, resulting in tool invocation failures.</p></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">Phidata</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;margin-right:auto;margin-left:auto;width:100%;height:auto" class="m-9e117634 mantine-Image-root" src="phidata_feature.jpg" alt="radar"/><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">In the ReAct workflow, Phidata passes the available tools to the LLM via the &quot;tools&quot; field. Unlike Llamaindex, which emphasizes the functionality and usage of tools in the system prompt, Phidata rarely invokes the code execution tool when processing queries from humaneval.</p></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">PydanticAI</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;margin-right:auto;margin-left:auto;width:50%;height:auto" class="m-9e117634 mantine-Image-root" src="radar_tools.jpg" alt="radar"/><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;margin-right:auto;margin-left:auto;width:100%;height:auto" class="m-9e117634 mantine-Image-root" src="pydantic_bug2.jpg" alt="radar"/><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Within the Pydantic ReAct framework, we observed multiple simultaneous invocations of the same tool, which may lead to inefficiencies. Additionally, similar to Phidata, the code execution tool was seldom triggered.<br/>Furthermore, the MoA implementation in the Pydantic framework is tool-based, and not all three models are invoked for every query.</p></div></div></main><footer class="footer_footer__mqdak"><div class="footer_inner__o6Jv8 m-7485cace mantine-Container-root"><div><p>AgentRace</p><p style="--text-fz:var(--mantine-font-size-xs);--text-lh:var(--mantine-line-height-xs);color:var(--mantine-color-dimmed)" class="mantine-focus-auto m-b6d8b162 mantine-Text-root" data-size="xs">The first benchmark specifically designed to systematically evaluate the efficiency of LLM agent frameworks across representative workloads.</p></div></div></footer></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{}},"page":"/bugsandfeatures","query":{},"buildId":"hqgkvujuo8_0LJtgbprH8","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>