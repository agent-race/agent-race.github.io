<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><script data-mantine-script="true">try {
  var _colorScheme = window.localStorage.getItem("mantine-color-scheme-value");
  var colorScheme = _colorScheme === "light" || _colorScheme === "dark" || _colorScheme === "auto" ? _colorScheme : "auto";
  var computedColorScheme = colorScheme !== "auto" ? colorScheme : window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
  document.documentElement.setAttribute("data-mantine-color-scheme", computedColorScheme);
} catch (e) {}
</script><link rel="preload" href="/_next/static/css/e55422db8ef0350a.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/e55422db8ef0350a.css" crossorigin="" data-n-g=""/><link rel="preload" href="/_next/static/css/a0262cf9ad81502e.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/a0262cf9ad81502e.css" crossorigin="" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-2c1f25ac8a9585fc.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-2c3044221d39fe2c.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-a5e61fdd3daae839.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-a728986f309b03d5.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/721-bab849efef7d2e94.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/136-ed7befffb9a4c0bc.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/insights-fce27a8bcf94f638.js" defer="" crossorigin=""></script><script src="/_next/static/u9_9I1WjJaPbdl1potu4w/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/u9_9I1WjJaPbdl1potu4w/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><header class="header_header__zJOD0"><title>AgentRace: Benchmarking Efficiency in LLM Agent Frameworks</title><meta property="og:title" content="AgentRace: Benchmarking Efficiency in LLM Agent Frameworks"/><meta property="og:description" content="A toolkit crafted specifically for the systematic evaluation of data privacy risks in LLMs, incorporating diverse attack and defense strategies, and handling various data types and metrics."/><div style="--container-size:var(--container-size-md)" class="header_inner__Gca1C m-7485cace mantine-Container-root" data-size="md"><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-visible-from-xs">AgentRace: Benchmarking Efficiency in LLM Agent Frameworks</p><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-hidden-from-xs">AgentRace</p> <div style="--group-gap:calc(0.3125rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="m-4081bf90 mantine-Group-root mantine-visible-from-md"><a href="/home" class="header_link__ne2MS"><div style="display:flex;gap:4px">Home</div></a><a href="/insights" class="header_link__ne2MS" data-active="true"><div style="display:flex;gap:4px">Insights</div></a><a href="/bugsandfeatures" class="header_link__ne2MS"><div style="display:flex;gap:4px">Bugs/Features</div></a><a href="/paper" class="header_link__ne2MS"><div style="display:flex;gap:4px">Paper</div></a><a href="https://github.com/agent-race/AgentRace" class="header_link__ne2MS"><div style="display:flex;gap:4px">GitHub<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-external-link" style="width:14px;height:14px"><path d="M12 6h-6a2 2 0 0 0 -2 2v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-6"></path><path d="M11 13l9 -9"></path><path d="M15 4h5v5"></path></svg></div></a></div><button style="--burger-size:var(--burger-size-md)" class="mantine-focus-auto m-fea6bf1a mantine-Burger-root m-87cf2631 mantine-UnstyledButton-root mantine-hidden-from-md" data-size="md" type="button" aria-haspopup="menu" aria-expanded="false" aria-controls="mantine-R5m3m-dropdown" id="mantine-R5m3m-target"><div class="m-d4fb9cad mantine-Burger-burger" data-reduce-motion="true"></div></button></div><script async="" src="https://us.umami.is/script.js" data-website-id="5d999a58-aa74-47db-897c-1c811cb73612"></script><script defer="" src="https://umami.xtra.science/script.js" data-website-id="81e4d054-90e2-428a-af65-f0a20b460201"></script></header><div style="height:calc(3.5rem * var(--mantine-scale))"> <!-- --> </div><main><div class="m-7485cace mantine-Container-root"><h1 style="--title-fw:var(--mantine-h1-font-weight);--title-lh:var(--mantine-h1-line-height);--title-fz:var(--mantine-h1-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="1">Insights</h1><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">Execution Time and Token Consumption</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><div style="--accordion-radius:var(--mantine-radius-md)" class="m-9bdbb667 mantine-Accordion-root" data-variant="contained" id="mantine-Raenm" data-accordion="true"><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Raenm-panel-LLM inference usually dominates runtime across all agent frameworks, and inefficient prompt engineering, such as appending full histories and using verbose prompts, exacerbates both latency and cost." id="mantine-Raenm-control-LLM inference usually dominates runtime across all agent frameworks, and inefficient prompt engineering, such as appending full histories and using verbose prompts, exacerbates both latency and cost."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">LLM inference usually dominates runtime across all agent frameworks, and inefficient prompt engineering, such as appending full histories and using verbose prompts, exacerbates both latency and cost.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-clock"><path d="M3 12a9 9 0 1 0 18 0a9 9 0 0 0 -18 0"></path><path d="M12 7v5l3 3"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Raenm-panel-LLM inference usually dominates runtime across all agent frameworks, and inefficient prompt engineering, such as appending full histories and using verbose prompts, exacerbates both latency and cost." aria-labelledby="mantine-Raenm-control-LLM inference usually dominates runtime across all agent frameworks, and inefficient prompt engineering, such as appending full histories and using verbose prompts, exacerbates both latency and cost."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><figure><div style="width:100%;display:flex;justify-content:center"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;max-width:700px;width:100%;height:auto" class="m-9e117634 mantine-Image-root" src="figure3.jpg" alt=""/></div><p style="color:var(--mantine-color-dimmed);text-align:center" class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Figure 3. Token consumption and execution time per query of different frameworks.</p></figure><div><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Figure 3. presents the breakdown of agent execution time across four benchmark scenarios. Across all settings, LLM inference consistently dominates runtime. Even in the GAIA scenario, which is explicitly designed to be tool-intensive and involves frequent calls to external APIs, LLM inference accounts for more than 85% of the total execution time in most frameworks. In simpler workflows such as HumanEval and AlpacaEval, the proportion exceeds 95%. This highlights that LLM inference, due to its computational demands and frequent invocation, remains the primary bottleneck in agent execution, regardless of the complexity or type of task.<br/>Moreover, we observe that the cost of LLM inference is further exacerbated by large variations in token efficiency across frameworks. There is a strong positive correlation between LLM inference time and token consumption. Some frameworks, notably CrewAI, LlamaIndex, and AgentScope, consistently exhibit higher token usage, leading to significantly prolonged inference times and increased resource consumption. We identify two main causes of token inefficiency: <span style="font-weight:bold">appending unnecessary history to prompts</span> and <span style="font-weight:bold">using verbose prompts</span>.<br/>We observe that CrewAI and AgentScope elevated token usage arises from their design choice. In their implementation, the LLM stores all intermediate inputs and outputs as memory and appends this memory to each new prompt. As a result, the prompt length—and thus token count—grows with every step of reasoning. <br/>In the ReAct workflow, LlamaIndex consumes a significant amount of prompts, primarily due to the observation portion returned to the LLM after tool invocation. Additionally, for queries that fail to execute successfully, the number of reasoning + action iterations increases, leading to a corresponding growth in the observation-related prompts.</p></div></div></div></div></div><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Raenm-panel-Token consumption may vary across frameworks even when executing the same workflow, owing to differences in implementation strategies." id="mantine-Raenm-control-Token consumption may vary across frameworks even when executing the same workflow, owing to differences in implementation strategies."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">Token consumption may vary across frameworks even when executing the same workflow, owing to differences in implementation strategies.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-dimensions"><path d="M3 5h11"></path><path d="M12 7l2 -2l-2 -2"></path><path d="M5 3l-2 2l2 2"></path><path d="M19 10v11"></path><path d="M17 19l2 2l2 -2"></path><path d="M21 12l-2 -2l-2 2"></path><path d="M3 10m0 2a2 2 0 0 1 2 -2h7a2 2 0 0 1 2 2v7a2 2 0 0 1 -2 2h-7a2 2 0 0 1 -2 -2z"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Raenm-panel-Token consumption may vary across frameworks even when executing the same workflow, owing to differences in implementation strategies." aria-labelledby="mantine-Raenm-control-Token consumption may vary across frameworks even when executing the same workflow, owing to differences in implementation strategies."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><p style="color:var(--mantine-color-blue-text);font-weight:700" class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-hidden-from-sm">Table: GAIA Detailed Results</p><table style="--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale));font-size:12px;margin-bottom:20px" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><thead class="m-b242d975 mantine-Table-thead"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" rowspan="2">Frameworks</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">Token</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="5">Time</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th">Prompt</th><th class="m-4e7aa4f3 mantine-Table-th">Output</th><th class="m-4e7aa4f3 mantine-Table-th">Total</th><th class="m-4e7aa4f3 mantine-Table-th">LLM</th><th class="m-4e7aa4f3 mantine-Table-th">Web Tool</th><th class="m-4e7aa4f3 mantine-Table-th">PDF Tool</th><th class="m-4e7aa4f3 mantine-Table-th">CSV Tool</th><th class="m-4e7aa4f3 mantine-Table-th">XLSX Tool</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">langchain</td><td class="m-4e7aa4ef mantine-Table-td">9358.35</td><td class="m-4e7aa4ef mantine-Table-td">637.92</td><td class="m-4e7aa4ef mantine-Table-td">9996.27</td><td class="m-4e7aa4ef mantine-Table-td">29.491</td><td class="m-4e7aa4ef mantine-Table-td">1.58856</td><td class="m-4e7aa4ef mantine-Table-td">0.02423455</td><td class="m-4e7aa4ef mantine-Table-td">0.00003333</td><td class="m-4e7aa4ef mantine-Table-td">0.06422606</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">autogen</td><td class="m-4e7aa4ef mantine-Table-td">1159.48</td><td class="m-4e7aa4ef mantine-Table-td">180.66</td><td class="m-4e7aa4ef mantine-Table-td">1340.15</td><td class="m-4e7aa4ef mantine-Table-td">8.464</td><td class="m-4e7aa4ef mantine-Table-td">9.4219</td><td class="m-4e7aa4ef mantine-Table-td">0.0009297</td><td class="m-4e7aa4ef mantine-Table-td">0.000336</td><td class="m-4e7aa4ef mantine-Table-td">0.002387</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">agentscope</td><td class="m-4e7aa4ef mantine-Table-td">23520.479</td><td class="m-4e7aa4ef mantine-Table-td">785.891</td><td class="m-4e7aa4ef mantine-Table-td">24306.37</td><td class="m-4e7aa4ef mantine-Table-td">41.17</td><td class="m-4e7aa4ef mantine-Table-td">7.291</td><td class="m-4e7aa4ef mantine-Table-td">0.217</td><td class="m-4e7aa4ef mantine-Table-td">0.000297</td><td class="m-4e7aa4ef mantine-Table-td">0.00405</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">crewai</td><td class="m-4e7aa4ef mantine-Table-td">33621.857</td><td class="m-4e7aa4ef mantine-Table-td">664.511</td><td class="m-4e7aa4ef mantine-Table-td">34286.369</td><td class="m-4e7aa4ef mantine-Table-td">67.68</td><td class="m-4e7aa4ef mantine-Table-td">4.031</td><td class="m-4e7aa4ef mantine-Table-td">0.00965</td><td class="m-4e7aa4ef mantine-Table-td">0.000196</td><td class="m-4e7aa4ef mantine-Table-td">0.00422</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">llamaindex</td><td class="m-4e7aa4ef mantine-Table-td">20935.364</td><td class="m-4e7aa4ef mantine-Table-td">304.976</td><td class="m-4e7aa4ef mantine-Table-td">21240.339</td><td class="m-4e7aa4ef mantine-Table-td">27.244</td><td class="m-4e7aa4ef mantine-Table-td">1.4399</td><td class="m-4e7aa4ef mantine-Table-td">0.0001352</td><td class="m-4e7aa4ef mantine-Table-td">0.00016616</td><td class="m-4e7aa4ef mantine-Table-td">0.004254</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">phidata/agno</td><td class="m-4e7aa4ef mantine-Table-td">6386.667</td><td class="m-4e7aa4ef mantine-Table-td">323.558</td><td class="m-4e7aa4ef mantine-Table-td">6710.224</td><td class="m-4e7aa4ef mantine-Table-td">14.375</td><td class="m-4e7aa4ef mantine-Table-td">1.83012</td><td class="m-4e7aa4ef mantine-Table-td">0.001147</td><td class="m-4e7aa4ef mantine-Table-td">0.0007207</td><td class="m-4e7aa4ef mantine-Table-td">0.003858</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">pydantic</td><td class="m-4e7aa4ef mantine-Table-td">14459.17</td><td class="m-4e7aa4ef mantine-Table-td">320.588</td><td class="m-4e7aa4ef mantine-Table-td">14779.758</td><td class="m-4e7aa4ef mantine-Table-td">23.779</td><td class="m-4e7aa4ef mantine-Table-td">1.2275</td><td class="m-4e7aa4ef mantine-Table-td">0.001395</td><td class="m-4e7aa4ef mantine-Table-td">0.0003148</td><td class="m-4e7aa4ef mantine-Table-td">0.003795</td></tr></tbody></table><table style="--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale));font-size:12px" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><caption class="m-9e5a3ac7 mantine-Table-caption" data-side="bottom">Table 4: GAIA Detailed Results</caption><thead class="m-b242d975 mantine-Table-thead"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" colSpan="8">Time</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th">TXT Tool</th><th class="m-4e7aa4f3 mantine-Table-th">DOCX Tool</th><th class="m-4e7aa4f3 mantine-Table-th">Audio Tool</th><th class="m-4e7aa4f3 mantine-Table-th">Vision Tool</th><th class="m-4e7aa4f3 mantine-Table-th">Video Tool</th><th class="m-4e7aa4f3 mantine-Table-th">Python Tool</th><th class="m-4e7aa4f3 mantine-Table-th">Total Tool Time</th><th class="m-4e7aa4f3 mantine-Table-th">Total Time</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">0.0004194</td><td class="m-4e7aa4ef mantine-Table-td">0.00009758</td><td class="m-4e7aa4ef mantine-Table-td">-</td><td class="m-4e7aa4ef mantine-Table-td">0.5345976</td><td class="m-4e7aa4ef mantine-Table-td">-</td><td class="m-4e7aa4ef mantine-Table-td">0.0152988</td><td class="m-4e7aa4ef mantine-Table-td">2.22746732</td><td class="m-4e7aa4ef mantine-Table-td">32.492</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">0.00002909</td><td class="m-4e7aa4ef mantine-Table-td">0.0002212</td><td class="m-4e7aa4ef mantine-Table-td">-</td><td class="m-4e7aa4ef mantine-Table-td">1.05489</td><td class="m-4e7aa4ef mantine-Table-td">-</td><td class="m-4e7aa4ef mantine-Table-td">0.00005333</td><td class="m-4e7aa4ef mantine-Table-td">10.4807</td><td class="m-4e7aa4ef mantine-Table-td">20.76</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">0.0000193</td><td class="m-4e7aa4ef mantine-Table-td">0.00000883</td><td class="m-4e7aa4ef mantine-Table-td">0.729</td><td class="m-4e7aa4ef mantine-Table-td">4.083</td><td class="m-4e7aa4ef mantine-Table-td">0.0000271</td><td class="m-4e7aa4ef mantine-Table-td">0.752</td><td class="m-4e7aa4ef mantine-Table-td">13.076</td><td class="m-4e7aa4ef mantine-Table-td">55.092</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">0.00123</td><td class="m-4e7aa4ef mantine-Table-td">0.000278</td><td class="m-4e7aa4ef mantine-Table-td">0.000346</td><td class="m-4e7aa4ef mantine-Table-td">0.03164</td><td class="m-4e7aa4ef mantine-Table-td">0.000999</td><td class="m-4e7aa4ef mantine-Table-td">0.09565</td><td class="m-4e7aa4ef mantine-Table-td">4.18</td><td class="m-4e7aa4ef mantine-Table-td">72.195</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">0.000034839</td><td class="m-4e7aa4ef mantine-Table-td">0.0001135</td><td class="m-4e7aa4ef mantine-Table-td">0.03341</td><td class="m-4e7aa4ef mantine-Table-td">0.8767</td><td class="m-4e7aa4ef mantine-Table-td">-</td><td class="m-4e7aa4ef mantine-Table-td">0.05782</td><td class="m-4e7aa4ef mantine-Table-td">2.4126</td><td class="m-4e7aa4ef mantine-Table-td">29.795</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">0.0002107</td><td class="m-4e7aa4ef mantine-Table-td">0.000073355</td><td class="m-4e7aa4ef mantine-Table-td">0.03821</td><td class="m-4e7aa4ef mantine-Table-td">1.4065</td><td class="m-4e7aa4ef mantine-Table-td">1.38445E-05</td><td class="m-4e7aa4ef mantine-Table-td">0.003035</td><td class="m-4e7aa4ef mantine-Table-td">3.2839</td><td class="m-4e7aa4ef mantine-Table-td">20.396</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">8.6865E-06</td><td class="m-4e7aa4ef mantine-Table-td">0.000056241</td><td class="m-4e7aa4ef mantine-Table-td">0.02965</td><td class="m-4e7aa4ef mantine-Table-td">1.2104</td><td class="m-4e7aa4ef mantine-Table-td">3.1952E-06</td><td class="m-4e7aa4ef mantine-Table-td">0.0001414</td><td class="m-4e7aa4ef mantine-Table-td">2.4732</td><td class="m-4e7aa4ef mantine-Table-td">26.238</td></tr></tbody></table><p style="color:var(--mantine-color-blue-text);font-weight:700" class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-hidden-from-sm">Table 5: HumanEval Detailed Results</p><table style="--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale));font-size:12px" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><caption class="m-9e5a3ac7 mantine-Table-caption" data-side="bottom">Table 5: HumanEval Detailed Results</caption><thead class="m-b242d975 mantine-Table-thead"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" rowspan="2">Framework</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">Token</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">Time</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th">Prompt</th><th class="m-4e7aa4f3 mantine-Table-th">Output</th><th class="m-4e7aa4f3 mantine-Table-th">Total</th><th class="m-4e7aa4f3 mantine-Table-th">LLM</th><th class="m-4e7aa4f3 mantine-Table-th">Code Executor</th><th class="m-4e7aa4f3 mantine-Table-th">Total</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">LangChain</td><td class="m-4e7aa4ef mantine-Table-td">6326.36</td><td class="m-4e7aa4ef mantine-Table-td">617.13</td><td class="m-4e7aa4ef mantine-Table-td">6943.49</td><td class="m-4e7aa4ef mantine-Table-td">23.221</td><td class="m-4e7aa4ef mantine-Table-td">0.0034</td><td class="m-4e7aa4ef mantine-Table-td">23.968</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">AutoGen</td><td class="m-4e7aa4ef mantine-Table-td">767.45</td><td class="m-4e7aa4ef mantine-Table-td">106.34</td><td class="m-4e7aa4ef mantine-Table-td">873.79</td><td class="m-4e7aa4ef mantine-Table-td">5.822</td><td class="m-4e7aa4ef mantine-Table-td">0.0002</td><td class="m-4e7aa4ef mantine-Table-td">5.846</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">AgentScope</td><td class="m-4e7aa4ef mantine-Table-td">3180.689</td><td class="m-4e7aa4ef mantine-Table-td">561.518</td><td class="m-4e7aa4ef mantine-Table-td">3742.207</td><td class="m-4e7aa4ef mantine-Table-td">11.738</td><td class="m-4e7aa4ef mantine-Table-td">0.131</td><td class="m-4e7aa4ef mantine-Table-td">11.906</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">CrewAI</td><td class="m-4e7aa4ef mantine-Table-td">10817.65</td><td class="m-4e7aa4ef mantine-Table-td">892.798</td><td class="m-4e7aa4ef mantine-Table-td">11710.45</td><td class="m-4e7aa4ef mantine-Table-td">24.22</td><td class="m-4e7aa4ef mantine-Table-td">0.0258</td><td class="m-4e7aa4ef mantine-Table-td">25.24</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">LlamaIndex</td><td class="m-4e7aa4ef mantine-Table-td">1985.6</td><td class="m-4e7aa4ef mantine-Table-td">342.793</td><td class="m-4e7aa4ef mantine-Table-td">2328.152</td><td class="m-4e7aa4ef mantine-Table-td">9.52</td><td class="m-4e7aa4ef mantine-Table-td">0.003069</td><td class="m-4e7aa4ef mantine-Table-td">9.611</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">Phidata</td><td class="m-4e7aa4ef mantine-Table-td">967.329</td><td class="m-4e7aa4ef mantine-Table-td">354.427</td><td class="m-4e7aa4ef mantine-Table-td">1321.756</td><td class="m-4e7aa4ef mantine-Table-td">7.181</td><td class="m-4e7aa4ef mantine-Table-td">-</td><td class="m-4e7aa4ef mantine-Table-td">9.692</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">PydanticAI</td><td class="m-4e7aa4ef mantine-Table-td">812.951</td><td class="m-4e7aa4ef mantine-Table-td">352.543</td><td class="m-4e7aa4ef mantine-Table-td">1165.494</td><td class="m-4e7aa4ef mantine-Table-td">5.258</td><td class="m-4e7aa4ef mantine-Table-td">0.000007158</td><td class="m-4e7aa4ef mantine-Table-td">5.276</td></tr></tbody></table><div style="display:flex;flex-direction:column;gap:32px"><table style="--table-caption-side:bottom;--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale))" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><thead class="m-b242d975 mantine-Table-thead"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" rowspan="3">Framework</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="9">Token</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">llama</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">qwen</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">deepseek</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th">prompt</th><th class="m-4e7aa4f3 mantine-Table-th">output</th><th class="m-4e7aa4f3 mantine-Table-th">total</th><th class="m-4e7aa4f3 mantine-Table-th">prompt</th><th class="m-4e7aa4f3 mantine-Table-th">output</th><th class="m-4e7aa4f3 mantine-Table-th">total</th><th class="m-4e7aa4f3 mantine-Table-th">prompt</th><th class="m-4e7aa4f3 mantine-Table-th">output</th><th class="m-4e7aa4f3 mantine-Table-th">total</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">LangChain</td><td class="m-4e7aa4ef mantine-Table-td">70.49</td><td class="m-4e7aa4ef mantine-Table-td">428.55</td><td class="m-4e7aa4ef mantine-Table-td">499.04</td><td class="m-4e7aa4ef mantine-Table-td">64.84</td><td class="m-4e7aa4ef mantine-Table-td">446.05</td><td class="m-4e7aa4ef mantine-Table-td">510.91</td><td class="m-4e7aa4ef mantine-Table-td">38.5</td><td class="m-4e7aa4ef mantine-Table-td">501.11</td><td class="m-4e7aa4ef mantine-Table-td">539.61</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">AutoGen</td><td class="m-4e7aa4ef mantine-Table-td">70.49</td><td class="m-4e7aa4ef mantine-Table-td">431.96</td><td class="m-4e7aa4ef mantine-Table-td">502.45</td><td class="m-4e7aa4ef mantine-Table-td">64.85</td><td class="m-4e7aa4ef mantine-Table-td">447.45</td><td class="m-4e7aa4ef mantine-Table-td">512.31</td><td class="m-4e7aa4ef mantine-Table-td">38.5</td><td class="m-4e7aa4ef mantine-Table-td">503.37</td><td class="m-4e7aa4ef mantine-Table-td">541.87</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">AgentScope</td><td class="m-4e7aa4ef mantine-Table-td">85.451</td><td class="m-4e7aa4ef mantine-Table-td">382.45</td><td class="m-4e7aa4ef mantine-Table-td">467.901</td><td class="m-4e7aa4ef mantine-Table-td">61.815</td><td class="m-4e7aa4ef mantine-Table-td">311.109</td><td class="m-4e7aa4ef mantine-Table-td">372.924</td><td class="m-4e7aa4ef mantine-Table-td">52.478</td><td class="m-4e7aa4ef mantine-Table-td">416.639</td><td class="m-4e7aa4ef mantine-Table-td">469.117</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">CrewAI</td><td class="m-4e7aa4ef mantine-Table-td">298.25</td><td class="m-4e7aa4ef mantine-Table-td">518.95</td><td class="m-4e7aa4ef mantine-Table-td">817.201</td><td class="m-4e7aa4ef mantine-Table-td">258.083</td><td class="m-4e7aa4ef mantine-Table-td">398.618</td><td class="m-4e7aa4ef mantine-Table-td">656.702</td><td class="m-4e7aa4ef mantine-Table-td">313.01</td><td class="m-4e7aa4ef mantine-Table-td">571.79</td><td class="m-4e7aa4ef mantine-Table-td">884.808</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">LlamaIndex</td><td class="m-4e7aa4ef mantine-Table-td">70.49</td><td class="m-4e7aa4ef mantine-Table-td">430.216</td><td class="m-4e7aa4ef mantine-Table-td">500.707</td><td class="m-4e7aa4ef mantine-Table-td">64.81</td><td class="m-4e7aa4ef mantine-Table-td">441.738</td><td class="m-4e7aa4ef mantine-Table-td">506.548</td><td class="m-4e7aa4ef mantine-Table-td">38.485</td><td class="m-4e7aa4ef mantine-Table-td">495.306</td><td class="m-4e7aa4ef mantine-Table-td">533.791</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">Phidata</td><td class="m-4e7aa4ef mantine-Table-td">118.846</td><td class="m-4e7aa4ef mantine-Table-td">438.078</td><td class="m-4e7aa4ef mantine-Table-td">556.924</td><td class="m-4e7aa4ef mantine-Table-td">93.899</td><td class="m-4e7aa4ef mantine-Table-td">463.795</td><td class="m-4e7aa4ef mantine-Table-td">557.694</td><td class="m-4e7aa4ef mantine-Table-td">83.391</td><td class="m-4e7aa4ef mantine-Table-td">440.691</td><td class="m-4e7aa4ef mantine-Table-td">524.082</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">PydanticAI</td><td class="m-4e7aa4ef mantine-Table-td">61.347</td><td class="m-4e7aa4ef mantine-Table-td">429.543</td><td class="m-4e7aa4ef mantine-Table-td">490.889</td><td class="m-4e7aa4ef mantine-Table-td">41.217</td><td class="m-4e7aa4ef mantine-Table-td">433.739</td><td class="m-4e7aa4ef mantine-Table-td">474.957</td><td class="m-4e7aa4ef mantine-Table-td">31.802</td><td class="m-4e7aa4ef mantine-Table-td">434.81</td><td class="m-4e7aa4ef mantine-Table-td">485.612</td></tr></tbody></table><table style="--table-caption-side:bottom;--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale))" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><thead class="m-b242d975 mantine-Table-thead"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3"> </th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="5">time</th><th class="m-4e7aa4f3 mantine-Table-th"> </th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">gpt</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="5"> </th><th class="m-4e7aa4f3 mantine-Table-th">agent1 (llama)</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th">prompt</th><th class="m-4e7aa4f3 mantine-Table-th">output</th><th class="m-4e7aa4f3 mantine-Table-th">total</th><th class="m-4e7aa4f3 mantine-Table-th">llama</th><th class="m-4e7aa4f3 mantine-Table-th">qwen</th><th class="m-4e7aa4f3 mantine-Table-th">deepseek</th><th class="m-4e7aa4f3 mantine-Table-th">aggregator</th><th class="m-4e7aa4f3 mantine-Table-th">total</th><th class="m-4e7aa4f3 mantine-Table-th">agent1 (llama)</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">1522.48</td><td class="m-4e7aa4ef mantine-Table-td">444.81</td><td class="m-4e7aa4ef mantine-Table-td">1967.29</td><td class="m-4e7aa4ef mantine-Table-td">8.275</td><td class="m-4e7aa4ef mantine-Table-td">4.48</td><td class="m-4e7aa4ef mantine-Table-td">23.084</td><td class="m-4e7aa4ef mantine-Table-td">10.699</td><td class="m-4e7aa4ef mantine-Table-td">36.502</td><td class="m-4e7aa4ef mantine-Table-td">165.07/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">1529.96</td><td class="m-4e7aa4ef mantine-Table-td">450.63</td><td class="m-4e7aa4ef mantine-Table-td">1980.59</td><td class="m-4e7aa4ef mantine-Table-td">7.812</td><td class="m-4e7aa4ef mantine-Table-td">3.977</td><td class="m-4e7aa4ef mantine-Table-td">26.745</td><td class="m-4e7aa4ef mantine-Table-td">8.274</td><td class="m-4e7aa4ef mantine-Table-td">36.854</td><td class="m-4e7aa4ef mantine-Table-td">209.08/44.01</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">1138.243</td><td class="m-4e7aa4ef mantine-Table-td">352.564</td><td class="m-4e7aa4ef mantine-Table-td">1490.807</td><td class="m-4e7aa4ef mantine-Table-td">6.063</td><td class="m-4e7aa4ef mantine-Table-td">3.415</td><td class="m-4e7aa4ef mantine-Table-td">13.726</td><td class="m-4e7aa4ef mantine-Table-td">8.89</td><td class="m-4e7aa4ef mantine-Table-td">32.119</td><td class="m-4e7aa4ef mantine-Table-td">284.078/118</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">11694.576</td><td class="m-4e7aa4ef mantine-Table-td">679.15</td><td class="m-4e7aa4ef mantine-Table-td">12373.72</td><td class="m-4e7aa4ef mantine-Table-td">8.835</td><td class="m-4e7aa4ef mantine-Table-td">3.837</td><td class="m-4e7aa4ef mantine-Table-td">21.946</td><td class="m-4e7aa4ef mantine-Table-td">23.114</td><td class="m-4e7aa4ef mantine-Table-td">64</td><td class="m-4e7aa4ef mantine-Table-td">514.962/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">42.083</td><td class="m-4e7aa4ef mantine-Table-td">350.386</td><td class="m-4e7aa4ef mantine-Table-td">392.47</td><td class="m-4e7aa4ef mantine-Table-td">6.069</td><td class="m-4e7aa4ef mantine-Table-td">4.787</td><td class="m-4e7aa4ef mantine-Table-td">20.829</td><td class="m-4e7aa4ef mantine-Table-td">5.849</td><td class="m-4e7aa4ef mantine-Table-td">27.318</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">3003.319</td><td class="m-4e7aa4ef mantine-Table-td">756.689</td><td class="m-4e7aa4ef mantine-Table-td">3760.009</td><td class="m-4e7aa4ef mantine-Table-td">6.152</td><td class="m-4e7aa4ef mantine-Table-td">4.707</td><td class="m-4e7aa4ef mantine-Table-td">16.456</td><td class="m-4e7aa4ef mantine-Table-td">14.208</td><td class="m-4e7aa4ef mantine-Table-td">50.217</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">1845.724</td><td class="m-4e7aa4ef mantine-Table-td">596.876</td><td class="m-4e7aa4ef mantine-Table-td">2442.6</td><td class="m-4e7aa4ef mantine-Table-td">6.503</td><td class="m-4e7aa4ef mantine-Table-td">3.441</td><td class="m-4e7aa4ef mantine-Table-td">17.79</td><td class="m-4e7aa4ef mantine-Table-td">27.486</td><td class="m-4e7aa4ef mantine-Table-td">46.45</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr></tbody></table><table style="--table-caption-side:bottom;--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale))" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><caption class="m-9e5a3ac7 mantine-Table-caption" data-side="bottom">Table 7: AlpacaEval Detailed Results</caption><thead class="m-b242d975 mantine-Table-thead"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" colSpan="5">Communication Size (content/wrapper bytes)</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th" colSpan="2">prompt to agent</th><th class="m-4e7aa4f3 mantine-Table-th" colSpan="3">agent to aggregator</th></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th class="m-4e7aa4f3 mantine-Table-th">agent2 (qwen)</th><th class="m-4e7aa4f3 mantine-Table-th">agent3 (deepseek)</th><th class="m-4e7aa4f3 mantine-Table-th">agent1 (llama)</th><th class="m-4e7aa4f3 mantine-Table-th">agent2 (qwen)</th><th class="m-4e7aa4f3 mantine-Table-th">agent3 (deepseek)</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">165.07/0</td><td class="m-4e7aa4ef mantine-Table-td">165.07/0</td><td class="m-4e7aa4ef mantine-Table-td">1983.02/3</td><td class="m-4e7aa4ef mantine-Table-td">2011.83/3</td><td class="m-4e7aa4ef mantine-Table-td">2072.98/3</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">209.08/44.01</td><td class="m-4e7aa4ef mantine-Table-td">209.08/44.01</td><td class="m-4e7aa4ef mantine-Table-td">2066.04/52.24</td><td class="m-4e7aa4ef mantine-Table-td">2071.24/57.38</td><td class="m-4e7aa4ef mantine-Table-td">2156.04/66.81</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">284.078/118</td><td class="m-4e7aa4ef mantine-Table-td">284.078/118</td><td class="m-4e7aa4ef mantine-Table-td">1659.318/124</td><td class="m-4e7aa4ef mantine-Table-td">1511.311/122</td><td class="m-4e7aa4ef mantine-Table-td">1889.247/126</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">483.740/0</td><td class="m-4e7aa4ef mantine-Table-td">619.516/0</td><td class="m-4e7aa4ef mantine-Table-td">2497.929/0</td><td class="m-4e7aa4ef mantine-Table-td">1754.701/0</td><td class="m-4e7aa4ef mantine-Table-td">2151.097/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">1171.078/889</td><td class="m-4e7aa4ef mantine-Table-td">1164.078/882</td><td class="m-4e7aa4ef mantine-Table-td">2022.417/33.689</td><td class="m-4e7aa4ef mantine-Table-td">2054.878/39.118</td><td class="m-4e7aa4ef mantine-Table-td">2116.377/48.641</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">341.160/0</td><td class="m-4e7aa4ef mantine-Table-td">343.219/0</td><td class="m-4e7aa4ef mantine-Table-td">6128.259/2639.113</td><td class="m-4e7aa4ef mantine-Table-td">6131.272/2629.426</td><td class="m-4e7aa4ef mantine-Table-td">5715.126/2465.817</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">95.425/0</td><td class="m-4e7aa4ef mantine-Table-td">97.116/0</td><td class="m-4e7aa4ef mantine-Table-td">2000.542/0</td><td class="m-4e7aa4ef mantine-Table-td">1927.093/0</td><td class="m-4e7aa4ef mantine-Table-td">1892.344/0</td></tr></tbody></table></div><div><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">In the results of ReAct workflow, it can be observed that even when using the same ReAct workflow, AgentScope exhibits a significant discrepancy in token usage between the GAIA and HumanEval datasets, with exceptionally high token consumption on GAIA. This is primarily because AgentScope includes the entire memory of the agent in the prompt during every LLM invocation. As the number of reasoning steps increases, the prompt length grows rapidly. While this issue is less apparent in the relatively simple HumanEval dataset, it becomes prominent in the more complex GAIA tasks.<br/>The high token usage observed in CrewAI&#x27;s ReAct workflow can be attributed to the same reason. In fact, this issue is even more pronounced in CrewAI than in AgentScope, with significantly elevated token consumption observed across both the GAIA and HumanEval datasets.<br/>In contrast, the majority of token consumption in LlamaIndex and Pydantic arises from the observation segments returned to the LLM after tool invocations. In the GAIA dataset, where tasks are complex and involve frequent tool usage, this results in substantial prompt token overhead.<br/>There are also some issues observed in the MoA workflow. For example, PydanticAI does not require the invocation of all sub-agents during MoA execution, thereby reducing token consumption and runtime overhead.<br/>Another example is that in the CrewAI framework, MoA is centrally managed by a global agent, which also plays the role of aggregation agent. The global agent receives the task and sequentially assigns it to sub-agents (e.g., agent1, agent2, agent3). Each sub-agent completes its part and returns the result to the global agent, which then decides the next step. After all agents have responded, the global agent summarizes the results and outputs the final answer.<br/>In this setup, the global agent calls the LLM multiple times—once after each sub-agent’s response. Because LLMs retain the full context of previous inputs and outputs in a single session, each new call includes all prior interactions. This leads to token accumulation, especially by the third or fourth step, where the prompt becomes much longer. As a result, total token usage becomes higher than in frameworks with different coordination or memory strategies.This phenomenon will become more apparent in Scalability part as the number of sub agents increases.</p></div></div></div></div></div><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Raenm-panel-Parallel invocation reduces overall runtime." id="mantine-Raenm-control-Parallel invocation reduces overall runtime."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">Parallel invocation reduces overall runtime.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-corner-up-right-double"><path d="M4 18v-6a3 3 0 0 1 3 -3h7"></path><path d="M10 13l4 -4l-4 -4m5 8l4 -4l-4 -4"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Raenm-panel-Parallel invocation reduces overall runtime." aria-labelledby="mantine-Raenm-control-Parallel invocation reduces overall runtime."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><div><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">In some frameworks such as PydanticAI, the total runtime is observed to be shorter than the sum of individual tool and LLM invocation times on datasets such as GAIA and MoA. This improvement is attributed to its parallel execution architecture and asynchronous scheduling, which enables simultaneous invocation of multiple tools or LLMs, thereby effectively reducing end-to-end latency.</p></div></div></div></div></div></div></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">Tool Calling</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><div style="--accordion-radius:var(--mantine-radius-md)" class="m-9bdbb667 mantine-Accordion-root" data-variant="contained" id="mantine-Ramnm" data-accordion="true"><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Ramnm-panel-Tool execution efficiency varies widely across frameworks, with search and figure-related tools introducing disproportionately high latency." id="mantine-Ramnm-control-Tool execution efficiency varies widely across frameworks, with search and figure-related tools introducing disproportionately high latency."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">Tool execution efficiency varies widely across frameworks, with search and figure-related tools introducing disproportionately high latency.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-tool"><path d="M7 10h3v-3l-3.5 -3.5a6 6 0 0 1 8 8l6 6a2 2 0 0 1 -3 3l-6 -6a6 6 0 0 1 -8 -8l3.5 3.5"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Ramnm-panel-Tool execution efficiency varies widely across frameworks, with search and figure-related tools introducing disproportionately high latency." aria-labelledby="mantine-Ramnm-control-Tool execution efficiency varies widely across frameworks, with search and figure-related tools introducing disproportionately high latency."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><figure><div style="width:100%;display:flex;justify-content:center"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;max-width:700px;width:100%;height:auto" class="m-9e117634 mantine-Image-root" src="Figure4.jpg" alt=""/></div><p style="color:var(--mantine-color-dimmed);text-align:center" class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Figure 4. The execution time per call for each tool.</p></figure><div><p></p><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">We analyze the execution cost of various tool types across multiple LLM agent frameworks, as illustrated in Figure 4. The results reveal substantial variation in tool execution efficiency between frameworks, particularly for high-cost operations. Among all tool categories, search and figure-related tools usually incur the highest latency, often dominating total tool execution time within a workflow.<br/>For instance, the figure loader takes 2.7 seconds to execute in CrewAI, but exceeds 30 seconds in AgentScope, indicating considerable framework-dependent overhead. In contrast, lightweight tools such as <span style="font-weight:bold;font-family:monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:3px;color:#d63384">txt_tool</span> and <span style="font-weight:bold;font-family:monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:3px;color:#d63384">docx_tool</span> typically complete in under a millisecond, demonstrating minimal variance. Tools like <span style="font-weight:bold;font-family:monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:3px;color:#d63384">pdf_tool</span> and <span style="font-weight:bold;font-family:monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:3px;color:#d63384">python_tool</span> exhibit moderate differences in runtime, depending on each framework’s implementation and I/O strategy. <br/>Additionally, some frameworks (e.g., AgentScope) show disproportionately high total tool processing time, driven primarily by inefficient handling of image processing or multimedia tasks. This highlights the importance of optimizing high-latency tools, particularly in scenarios where tool invocation is frequent or tightly coupled with LLM inference. <br/>While LLM inference remains the dominant bottleneck in most of our benchmarks, more complex, tool-heavy scenarios, such as document analysis or multimodal agent tasks, may shift the performance bottleneck toward tool execution. Frameworks aiming to support such use cases must pay greater attention to optimizing tool orchestration and external API integration.</p></div></div></div></div></div></div></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">RAG</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><div style="--accordion-radius:var(--mantine-radius-md)" class="m-9bdbb667 mantine-Accordion-root" data-variant="contained" id="mantine-Raunm" data-accordion="true"><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Raunm-panel-While agents usually involve external databases for information retrieval, the database performance is overlooked in several frameworks. Vector database is recommended." id="mantine-Raunm-control-While agents usually involve external databases for information retrieval, the database performance is overlooked in several frameworks. Vector database is recommended."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">While agents usually involve external databases for information retrieval, the database performance is overlooked in several frameworks. Vector database is recommended.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-database"><path d="M12 6m-8 0a8 3 0 1 0 16 0a8 3 0 1 0 -16 0"></path><path d="M4 6v6a8 3 0 0 0 16 0v-6"></path><path d="M4 12v6a8 3 0 0 0 16 0v-6"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Raunm-panel-While agents usually involve external databases for information retrieval, the database performance is overlooked in several frameworks. Vector database is recommended." aria-labelledby="mantine-Raunm-control-While agents usually involve external databases for information retrieval, the database performance is overlooked in several frameworks. Vector database is recommended."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><div><div style="width:100%;display:flex;justify-content:center"><img style="--image-radius:var(--mantine-radius-md);--image-object-fit:contain;max-width:700px;width:100%;height:auto" class="m-9e117634 mantine-Image-root" src="figure3.jpg" alt=""/></div><p style="color:var(--mantine-color-dimmed);text-align:center" class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Figure 3. Token consumption and execution time per query of different frameworks.</p><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">While RAG workflows are increasingly adopted to enhance factual grounding, our benchmarking reveals that database performance, particularly during embedding and retrieval, is a critical yet frequently neglected factor. Figure 3(c). illustrates the variation in retrieval latency across frameworks, exposing significant performance disparities.<br/>One notable example is AgentScope, which demonstrates high vectorization latency. This stems from its design: during the database setup phase, AgentScope invokes a large embedding model to compute dense vector representations. The latency of this embedding model, often implemented as a separate LLM call, substantially increases the overall vectorization time. Similarly, Phidata exhibits elevated vectorization latency due to its use of a two-step pipeline. First, its built-in <span style="font-weight:bold;font-family:monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:3px;color:#d63384">csv_tool</span> loads documents row-by-row; then, it applies a SentenceTransformer model to compute embeddings. Our benchmark confirms that Phidata&#x27;s <span style="font-weight:bold;font-family:monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:3px;color:#d63384">csv_tool</span> itself is a relatively slow component, compounding the overall vectorization time. From our observation, vector databases such as Faiss are faster than other implementations.<br/>These observations highlight the need for more attention to retrieval pipeline design, especially in frameworks that aim to support real-time or large-scale RAG deployments. Optimization opportunities include batching document embeddings, using faster embedding models, minimizing redundant file reads, and caching frequent queries.</p></div></div></div></div></div></div></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">Communication Size</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><div style="--accordion-radius:var(--mantine-radius-md)" class="m-9bdbb667 mantine-Accordion-root" data-variant="contained" id="mantine-Rb6nm" data-accordion="true"><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Rb6nm-panel-Inefficient communication architecture and package design lead to high communication overhead in the multi-agent setting." id="mantine-Rb6nm-control-Inefficient communication architecture and package design lead to high communication overhead in the multi-agent setting."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">Inefficient communication architecture and package design lead to high communication overhead in the multi-agent setting.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-package"><path d="M12 3l8 4.5l0 9l-8 4.5l-8 -4.5l0 -9l8 -4.5"></path><path d="M12 12l8 -4.5"></path><path d="M12 12l0 9"></path><path d="M12 12l-8 -4.5"></path><path d="M16 5.25l-8 4.5"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Rb6nm-panel-Inefficient communication architecture and package design lead to high communication overhead in the multi-agent setting." aria-labelledby="mantine-Rb6nm-control-Inefficient communication architecture and package design lead to high communication overhead in the multi-agent setting."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><div><p style="color:var(--mantine-color-pink-text);font-weight:700" class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-hidden-from-sm">Get a better experience on larger screens</p><table style="--table-caption-side:bottom;--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale));font-size:12px" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><caption class="m-9e5a3ac7 mantine-Table-caption" data-side="bottom">Table 2: Communication size between agents (Unit: Byte). We report the content size (e.g., the transferred outputs from the last agent) and overhead size (e.g., header), separated by /.</caption><thead class="m-b242d975 mantine-Table-thead"><tr style="border-top:2pt solid #CED4DA;" class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1"></th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1"></th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">LangChain</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">AutoGen</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">AgentScope</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">CrewAI</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">LlamaIndex</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">Phidata</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">PydanticAI</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td style="text-align:center" class="m-4e7aa4ef mantine-Table-td" rowspan="3">From Global Agent</td><td class="m-4e7aa4ef mantine-Table-td">Agent1</td><td class="m-4e7aa4ef mantine-Table-td">165.07/0</td><td class="m-4e7aa4ef mantine-Table-td">209.08/44.01</td><td class="m-4e7aa4ef mantine-Table-td">284.078/0</td><td class="m-4e7aa4ef mantine-Table-td">514.962/0</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">Agent2</td><td class="m-4e7aa4ef mantine-Table-td">165.07/0</td><td class="m-4e7aa4ef mantine-Table-td">209.08/44.01</td><td class="m-4e7aa4ef mantine-Table-td">284.078/0</td><td class="m-4e7aa4ef mantine-Table-td">483.740/0</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">Agent3</td><td class="m-4e7aa4ef mantine-Table-td">165.07/0</td><td class="m-4e7aa4ef mantine-Table-td">209.08/44.01</td><td class="m-4e7aa4ef mantine-Table-td">284.078/0</td><td class="m-4e7aa4ef mantine-Table-td">619.516/0</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td style="text-align:center" class="m-4e7aa4ef mantine-Table-td" rowspan="3">To Aggregation Agent</td><td class="m-4e7aa4ef mantine-Table-td">Agent1</td><td class="m-4e7aa4ef mantine-Table-td">1983.02/3</td><td class="m-4e7aa4ef mantine-Table-td">2066.04/52.4</td><td class="m-4e7aa4ef mantine-Table-td">1659.318/0</td><td class="m-4e7aa4ef mantine-Table-td">2497.929/0</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">Agent2</td><td class="m-4e7aa4ef mantine-Table-td">2011.83/3</td><td class="m-4e7aa4ef mantine-Table-td">2071.24/57.38</td><td class="m-4e7aa4ef mantine-Table-td">1511.311/0</td><td class="m-4e7aa4ef mantine-Table-td">1754.701/0</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">Agent3</td><td class="m-4e7aa4ef mantine-Table-td">2072.98/3</td><td class="m-4e7aa4ef mantine-Table-td">2156.04/66.81</td><td class="m-4e7aa4ef mantine-Table-td">1889.247/0</td><td class="m-4e7aa4ef mantine-Table-td">2151.097/0</td><td class="m-4e7aa4ef mantine-Table-td">1180.078/898</td><td class="m-4e7aa4ef mantine-Table-td">354.508/0</td><td class="m-4e7aa4ef mantine-Table-td">96.022/0</td></tr></tbody></table><p></p><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">In multi-agent frameworks, communication between agents is often overlooked as a source of inefficiency. However, our analysis reveals large discrepancies in communication size across frameworks, as shown in Table 2. These differences arise not only from framework-specific message formats but also from architectural design choices, especially in multi-agent workflows like MoA.<br/>Notably, frameworks such as CrewAI, which adopt a centralized communication pattern, exhibit significantly higher communication costs. In these designs, a central agent coordinates multiple sub-agents by sequentially delegating subtasks and collecting responses. For example, in CrewAI&#x27;s MoA implementation, the center agent queries three sub-agents in sequence and aggregates their outputs. Each LLM invocation by the center agent accumulates prior messages in memory, causing the prompt size and the communication payload to grow linearly with the number of sub-agents. Phidata, on the other hand, incurs substantial communication overhead due to its design. In addition to the core message, it returns a duplicated <span style="font-weight:bold">content</span> field that mirrors the final message. This, combined with additional metadata fields, results in large overhead sizes.<br/>These findings indicate that communication cost is not merely a function of task complexity but also of framework design. In large-scale deployments or bandwidth-constrained environments, excessive inter-agent message sizes, especially those driven by redundant content or sequential message accumulation, can significantly impact system performance and cost. Future agent frameworks should consider streamlined communication protocols, selective message summarization, or compressing intermediate results to reduce unnecessary transfer overhead.</p></div></div></div></div></div></div></div><h2 style="--title-fw:var(--mantine-h2-font-weight);--title-lh:var(--mantine-h2-line-height);--title-fz:var(--mantine-h2-font-size)" class="common_pagetitle__4xBA6 m-8a5d1357 mantine-Title-root" data-order="2">Accuracy</h2><div style="--stack-gap:var(--mantine-spacing-sm);--stack-align:stretch;--stack-justify:flex-start;background:var(--mantine-color-body)" class="m-6d731127 mantine-Stack-root"><div style="--accordion-radius:var(--mantine-radius-md)" class="m-9bdbb667 mantine-Accordion-root" data-variant="contained" id="mantine-Rbenm" data-accordion="true"><div class="m-1f921b3b m-9bd7b098 mantine-Accordion-item"><button class="mantine-focus-auto m-4271d21b m-4ba585b8 mantine-Accordion-control m-87cf2631 mantine-UnstyledButton-root" data-accordion-control="true" data-chevron-position="right" type="button" aria-expanded="false" aria-controls="mantine-Rbenm-panel-The complete absence of output constraints in LLMs may lead to tool invocation failures, whereas excessively strict output validation can incur substantial token overhead and decrease the response success rate." id="mantine-Rbenm-control-The complete absence of output constraints in LLMs may lead to tool invocation failures, whereas excessively strict output validation can incur substantial token overhead and decrease the response success rate."><span class="m-3f35ae96 mantine-Accordion-chevron" data-position="right"><svg viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale));display:block"><path d="M3.13523 6.15803C3.3241 5.95657 3.64052 5.94637 3.84197 6.13523L7.5 9.56464L11.158 6.13523C11.3595 5.94637 11.6759 5.95657 11.8648 6.15803C12.0536 6.35949 12.0434 6.67591 11.842 6.86477L7.84197 10.6148C7.64964 10.7951 7.35036 10.7951 7.15803 10.6148L3.15803 6.86477C2.95657 6.67591 2.94637 6.35949 3.13523 6.15803Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span><span class="m-df3ffa0f mantine-Accordion-label">The complete absence of output constraints in LLMs may lead to tool invocation failures, whereas excessively strict output validation can incur substantial token overhead and decrease the response success rate.</span><span class="m-9bd771fe mantine-Accordion-icon" data-chevron-position="right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#41B755" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-components"><path d="M3 12l3 3l3 -3l-3 -3z"></path><path d="M15 12l3 3l3 -3l-3 -3z"></path><path d="M9 6l3 3l3 -3l-3 -3z"></path><path d="M9 18l3 3l3 -3l-3 -3z"></path></svg></span></button><div style="box-sizing:border-box;display:none;height:0;overflow:hidden" class="m-df78851f mantine-Accordion-panel" aria-hidden="true" role="region" id="mantine-Rbenm-panel-The complete absence of output constraints in LLMs may lead to tool invocation failures, whereas excessively strict output validation can incur substantial token overhead and decrease the response success rate." aria-labelledby="mantine-Rbenm-control-The complete absence of output constraints in LLMs may lead to tool invocation failures, whereas excessively strict output validation can incur substantial token overhead and decrease the response success rate."><div style="opacity:0;transition:opacity 200ms ease"><div class="m-4ba554d4 mantine-Accordion-content"><div><p style="color:var(--mantine-color-pink-text);font-weight:700" class="mantine-focus-auto m-b6d8b162 mantine-Text-root mantine-hidden-from-sm">Get a better experience on larger screens</p><table style="--table-caption-side:bottom;--table-vertical-spacing:calc(0.4375rem * var(--mantine-scale));font-size:12px" class="m-b23fa0ef mantine-Table-table" data-with-table-border="true"><caption class="m-9e5a3ac7 mantine-Table-caption" data-side="bottom">Table 3: The accuracy of each framework on each dataset</caption><thead class="m-b242d975 mantine-Table-thead"><tr style="border-top:2pt solid #CED4DA;" class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">Datasets</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">LangChain</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">AutoGen</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">AgentScope</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">CrewAI</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">LlamaIndex</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">Phidata</th><th style="text-align:center" class="m-4e7aa4f3 mantine-Table-th" rowspan="1">PydanticAI</th></tr></thead><tbody class="m-b2404537 mantine-Table-tbody"><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">GAIA</td><td class="m-4e7aa4ef mantine-Table-td">0.1515</td><td class="m-4e7aa4ef mantine-Table-td">0.1030</td><td class="m-4e7aa4ef mantine-Table-td">0.2000</td><td class="m-4e7aa4ef mantine-Table-td">0.1697</td><td class="m-4e7aa4ef mantine-Table-td">0.0788</td><td class="m-4e7aa4ef mantine-Table-td">0.2182</td><td class="m-4e7aa4ef mantine-Table-td">0.1394</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">HumanEval</td><td class="m-4e7aa4ef mantine-Table-td">0.573</td><td class="m-4e7aa4ef mantine-Table-td">0.884</td><td class="m-4e7aa4ef mantine-Table-td">0.884</td><td class="m-4e7aa4ef mantine-Table-td">0.872</td><td class="m-4e7aa4ef mantine-Table-td">0.872</td><td class="m-4e7aa4ef mantine-Table-td">0.902</td><td class="m-4e7aa4ef mantine-Table-td">0.921</td></tr><tr class="m-4e7aa4fd mantine-Table-tr" data-with-row-border="true" data-hover="true"><td class="m-4e7aa4ef mantine-Table-td">MMLU</td><td class="m-4e7aa4ef mantine-Table-td">0.820</td><td class="m-4e7aa4ef mantine-Table-td">0.817</td><td class="m-4e7aa4ef mantine-Table-td">0.827</td><td class="m-4e7aa4ef mantine-Table-td">0.813</td><td class="m-4e7aa4ef mantine-Table-td">0.745</td><td class="m-4e7aa4ef mantine-Table-td">0.792</td><td class="m-4e7aa4ef mantine-Table-td">0.788</td></tr></tbody></table><p></p><h4 style="--title-fw:var(--mantine-h4-font-weight);--title-lh:var(--mantine-h4-line-height);--title-fz:var(--mantine-h4-font-size)" class="m-8a5d1357 mantine-Title-root" data-order="4">Takeaways:</h4><p class="mantine-focus-auto m-b6d8b162 mantine-Text-root">Some frameworks, such as LlamaIndex, require tool inputs to conform to a strict dictionary format. However, GPT-4o does not consistently produce structured outputs that align with these expectations, leading to frequent tool invocation failures, which caused a lower accuracy in GAIA dataset. This issue can be partially mitigated if the framework explicitly enforces the format requirement during the registration phase or input schema definition.<br/>In contrast, other frameworks such as LangChain adopt stricter enforcement mechanisms. ReAct-style agents in these systems perform rigid output validation and initiate automatic retries when the model&#x27;s response deviates from the expected invocation structure. While such mechanisms increase robustness against malformed outputs, they may backfire in certain scenarios. <br/>In our evaluation, we found that when the model skips tool invocation and instead provides a direct answer (this happens especially with some of the simpler queries in the HumanEval dataset), the framework retries the prompt, often multiple times. Each retry includes previous failed attempts in the context, leading to a rapid increase in prompt length and token consumption as well as a lower likelihood of producing a clean, valid output on later attempts.<br/>An additional point to clarify is that the GAIA dataset exhibits relatively low accuracy. This is primarily because GAIA tasks often require complex task planning and the use of multiple tools, posing significant challenges for all evaluated frameworks. It is important to note that the primary focus of this study is not on accuracy, but rather on comparing the performance overhead (e.g., time, token usage) across different frameworks. Therefore, we ensured that the accuracy across frameworks remains broadly comparable, without conducting detailed task-level progress analysis as seen in some related work. By carefully controlling experimental parameters, the fairness of our comparisons remains valid, even in the presence of lower absolute accuracy.</p></div></div></div></div></div></div></div></div></main><footer class="footer_footer__mqdak"><div class="footer_inner__o6Jv8 m-7485cace mantine-Container-root"><div><p>AgentRace</p><p style="--text-fz:var(--mantine-font-size-xs);--text-lh:var(--mantine-line-height-xs);color:var(--mantine-color-dimmed)" class="mantine-focus-auto m-b6d8b162 mantine-Text-root" data-size="xs">The first benchmark specifically designed to systematically evaluate the efficiency of LLM agent frameworks across representative workloads.</p></div></div></footer></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{}},"page":"/insights","query":{},"buildId":"u9_9I1WjJaPbdl1potu4w","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>